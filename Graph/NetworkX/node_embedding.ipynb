{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29dd0d25-8e17-4104-a862-60e7b048a0f6",
   "metadata": {},
   "source": [
    "# Node embeddings\n",
    "\n",
    "Graph embeddings are the transformation of property graphs to a vector or a set of vectors. Embedding should capture the graph topology, node-to-node relationships, and other relevant information about graphs, subgraphs, and nodes.\n",
    "\n",
    "Usage:\n",
    "- Link prediction\n",
    "- Node classification\n",
    "- Node clustering (community detection)\n",
    "- Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1af351-6485-40be-a7e1-3a2bccbad6d6",
   "metadata": {},
   "source": [
    "## Node classification\n",
    "\n",
    "The main steps of the node classification technique are:\n",
    "1. Load the graph.\n",
    "2. Sample a number of random nodes (just to make the algorithm quicker).\n",
    "3. Calculate and/or load the node embeddings.\n",
    "4. Split the graph into a train and test set.\n",
    "5. Train the ML classifier.\n",
    "6. Test the ML classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f75fba-8c58-4144-90a6-4094c268c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"./data/graph-large\"):\n",
    "    os.makedirs(\"./data/graph-large\")\n",
    "    \n",
    "!wget -qO \"./data/graph-large/git_nodes.csv\" \"https://github.com/memgraph/graph-analytics-course/raw/master/lecture-5/node-classification/git_nodes.csv\"\n",
    "!wget -qO \"./data/graph-large/git_edges.csv\" \"https://github.com/memgraph/graph-analytics-course/raw/master/lecture-5/node-classification/git_edges.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fec15ec-fe8f-44a4-b992-69d7678e5cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-09 02:44:26.530885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-09 02:44:26.608292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-09 02:44:26.609333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-09 02:44:26.611051: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-09 02:44:26.612101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-09 02:44:26.612685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-09 02:44:26.613241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-09 02:44:27.104096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-09 02:44:27.104544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-09 02:44:27.104949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-09 02:44:27.105311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4368 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660, pci bus id: 0000:07:00.0, compute capability: 7.5\n",
      "100%|██████████| 37700/37700 [00:05<00:00, 6471.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of random walks: 100000\n",
      "Accuracy classification score: 0.7915\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the graph, \n",
    "# Create a NetworkX graph from files\n",
    "def load_graph(edges_file_path, nodes_file_path):\n",
    "    edges = pd.read_csv(edges_file_path, sep=',')\n",
    "    nodes = pd.read_csv(nodes_file_path, sep=',')\n",
    "    G = nx.from_pandas_edgelist(edges, 'id_1', 'id_2')\n",
    "    nx.set_node_attributes(G, pd.Series(nodes.developer_type, \n",
    "        index=nodes.id).to_dict(), 'developer_type')\n",
    "    nx.set_node_attributes(G, pd.Series(nodes.id, \n",
    "        index=nodes.id).to_dict(), 'id')\n",
    "    return G\n",
    "\n",
    "# Sampling random nodes\n",
    "# Select defined number of random nodes from a graph\n",
    "def sample_graph(G, number_of_samples, seed):\n",
    "    random.seed(seed)\n",
    "    H = G.copy()\n",
    "    samples = random.sample(list(G.nodes()), number_of_samples)\n",
    "    for n in tqdm(G):\n",
    "        if n not in samples:\n",
    "            H.remove_node(n)\n",
    "    H = StellarGraph.from_networkx(H)\n",
    "    return H\n",
    "\n",
    "# Load node embeddings from a file into a dictionary\n",
    "def load_embedding(file_path):\n",
    "    embedding_dict = {}\n",
    "    first_line = True\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                continue\n",
    "            vector = [float(i) for i in line.strip().split()]\n",
    "            embedding_dict[int(vector[0])] = vector[1:]\n",
    "        f.close()\n",
    "    return embedding_dict\n",
    "\n",
    "# Calculate and/or load the node embeddings\n",
    "def calculate_embeddings(recalculate_embeddings, G, embeddings_file_path):\n",
    "    if recalculate_embeddings == True:\n",
    "        rw = BiasedRandomWalk(G)\n",
    "        \n",
    "        walks = rw.run(nodes=list(G.nodes()), length=32, n=10, p=0.5, q=2.0)\n",
    "        print(\"Number of random walks: {}\".format(len(walks)))\n",
    "        str_walks = [[str(n) for n in walk] for walk in walks]\n",
    "        \n",
    "        model = Word2Vec(str_walks, vector_size=128, window=5, min_count=0,\n",
    "            sg=1, workers=2, epochs=1)\n",
    "        model.wv.save_word2vec_format(embeddings_file_path)\n",
    "    return load_embedding(embeddings_file_path)\n",
    "\n",
    "# Split the graph into a train and test set\n",
    "def split_data(G_nx, embeddings):\n",
    "    X = []\n",
    "    y = []\n",
    "    for x in embeddings.keys():\n",
    "        X.append(embeddings[x])\n",
    "        y.append(G_nx.nodes[x]['developer_type'])\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Train the ML classifier\n",
    "def train_classifier(X_train, y_train):\n",
    "    clf = LogisticRegressionCV(Cs=10, cv=10, scoring='accuracy',\n",
    "        verbose=False, max_iter=3000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "# Test the ML classfier\n",
    "def test_classifier(X_test, y_test, clf):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"Accuracy classification score: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "def main():\n",
    "    G_nx = load_graph('./data/graph-large/git_edges.csv', \n",
    "        './data/graph-large/git_nodes.csv')\n",
    "    G = sample_graph(G_nx, 10000, 0)\n",
    "    embeddings = calculate_embeddings(True, G, \n",
    "        './data/graph-large/embeddings_node_classify.txt')\n",
    "    X_train, X_test, y_train, y_test = split_data(G_nx, embeddings)\n",
    "    clf = train_classifier(X_train, y_train)\n",
    "    test_classifier(X_test, y_test, clf)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec5ac0-3b7b-4101-8ac0-10c238339fac",
   "metadata": {},
   "source": [
    "## Link prediction\n",
    "\n",
    "The main steps of the link prediction technique are:\n",
    "1. Load the graph.\n",
    "2. Sample a number of random nodes (just to make the algorithm quicker).\n",
    "3. Calculate and/or load the node embeddings.\n",
    "4. Split the graph into a train and test set.\n",
    "5. Train the ML classifier.\n",
    "6. Test the ML classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f9ebc2e-a672-432f-aecb-f62a2b034ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37700/37700 [00:05<00:00, 6323.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of random walks: 100000\n",
      "** Sampled 2154 positive and 2154 negative edges. **\n",
      "** Sampled 1938 positive and 1938 negative edges. **\n",
      "ROC AUC score: 0.9168214175177964\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from gensim.models import Word2Vec\n",
    "from stellargraph.data import EdgeSplitter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Load the graph\n",
    "# Create a NetworkX graph from files\n",
    "def load_graph(edges_file_path, nodes_file_path):\n",
    "    edges = pd.read_csv(edges_file_path, sep=',')\n",
    "    nodes = pd.read_csv(nodes_file_path, sep=',')\n",
    "    G = nx.from_pandas_edgelist(edges, 'id_1', 'id_2')\n",
    "    nx.set_node_attributes(G, pd.Series(nodes.developer_type, \n",
    "        index=nodes.id).to_dict(), 'developer_type')\n",
    "    nx.set_node_attributes(G, pd.Series(nodes.id, \n",
    "        index=nodes.id).to_dict(), 'id')\n",
    "    return G\n",
    "\n",
    "# Sampling random nodes\n",
    "# Select definied number of random nodes from a graph\n",
    "def sample_graph(G, number_of_samples, seed):\n",
    "    random.seed(seed)\n",
    "    H = G.copy()\n",
    "    samples = random.sample(list(G.nodes()), number_of_samples)\n",
    "    for n in tqdm(G):\n",
    "        if n not in samples:\n",
    "            H.remove_node(n)\n",
    "    H = StellarGraph.from_networkx(H)\n",
    "    return H\n",
    "    \n",
    "# Load node embeddings from a file into a dictionary\n",
    "def load_embedding(file_path):\n",
    "    embedding_dict = {}\n",
    "    first_line = True\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                continue\n",
    "            vector = [float(i) for i in line.strip().split()]\n",
    "            embedding_dict[int(vector[0])] = vector[1:]\n",
    "        f.close()\n",
    "    return embedding_dict\n",
    "\n",
    "# Calculate and/or load the node embeddings\n",
    "def calculate_embeddings(recalculate_embeddings, G, embeddings_file_path):\n",
    "    if recalculate_embeddings == True:\n",
    "        rw = BiasedRandomWalk(G)\n",
    "        \n",
    "        walks = rw.run(nodes=list(G.nodes()), length=32, n=10, p=0.5, q=2.0)\n",
    "        print(\"Number of random walks: {}\".format(len(walks)))\n",
    "        str_walks = [[str(n) for n in walk] for walk in walks]\n",
    "        \n",
    "        model = Word2Vec(str_walks, vector_size=128, window=5, min_count=0,\n",
    "            sg=1, workers=2, epochs=1)\n",
    "        model.wv.save_word2vec_format(embeddings_file_path)\n",
    "    return load_embedding(embeddings_file_path)\n",
    "\n",
    "# Split the graph into a train and test set\n",
    "def split_data(G):\n",
    "    edge_splitter_test = EdgeSplitter(G)\n",
    "    graph_test, X_test, y_test = edge_splitter_test.train_test_split(\n",
    "        p=0.1, method='global')\n",
    "    \n",
    "    edge_splitter_train = EdgeSplitter(graph_test, G)\n",
    "    _, X_train, y_train = edge_splitter_train.train_test_split(\n",
    "        p=0.1, method='global')\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def operator_avg(u, v):\n",
    "    u = np.array(u)\n",
    "    v = np.array(v)\n",
    "    return (u + v) / 2.0\n",
    "\n",
    "# Transform links to features\n",
    "def link_examples_to_features(X_train, embeddings, binary_operator):\n",
    "    return [binary_operator(embeddings[src], embeddings[dst])\n",
    "        for src, dst in X_train\n",
    "    ]\n",
    "\n",
    "# Train the ML classifier\n",
    "def train_classifier(X_train, y_train, embeddings, binary_operator):\n",
    "    clf = LogisticRegressionCV(Cs=10, cv=10, scoring='roc_auc',\n",
    "        max_iter=30000)\n",
    "    X_features = link_examples_to_features(X_train, \n",
    "        embeddings, binary_operator)\n",
    "    clf.fit(X_features, y_train)\n",
    "    return clf\n",
    "\n",
    "def evaluate_roc_auc(clf, X_features, y):\n",
    "    predicted = clf.predict_proba(X_features)\n",
    "    positive_column = list(clf.classes_).index(1)\n",
    "    return roc_auc_score(y, predicted[:, positive_column])\n",
    "\n",
    "# Test the ML clssifier\n",
    "def test_classifier(X_test, y_test, embeddings, binary_operator, clf):\n",
    "    X_features = link_examples_to_features(X_test, \n",
    "        embeddings, binary_operator)\n",
    "    score = evaluate_roc_auc(clf, X_features, y_test)\n",
    "    print(f\"ROC AUC score: {score}\")\n",
    "    \n",
    "def main():\n",
    "    G_nx = load_graph('./data/graph-large/git_edges.csv', \n",
    "        './data/graph-large/git_nodes.csv')\n",
    "    G = sample_graph(G_nx, 10000, 0)\n",
    "    embeddings = calculate_embeddings(True, G, \n",
    "        './data/graph-large/embeddings_link_predict.txt')\n",
    "    X_train, y_train, X_test, y_test = split_data(G)\n",
    "    clf = train_classifier(X_train, y_train, embeddings, operator_avg)\n",
    "    test_classifier(X_test, y_test, embeddings, operator_avg, clf)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
